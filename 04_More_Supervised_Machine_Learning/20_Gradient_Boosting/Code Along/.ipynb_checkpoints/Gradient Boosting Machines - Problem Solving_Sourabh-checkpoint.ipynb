{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCI Adult Data Set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has details of 32561 people with the following 14 features:\n",
    "\n",
    "[Census Income Dataset](https://archive.ics.uci.edu/ml/datasets/adult)\n",
    "\n",
    "![](adult.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report , accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country salary  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40           Cuba  <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"adult1.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data by completing the following tasks?\n",
    "- How many men and women (sex feature) are represented in this dataset? \n",
    "\n",
    "- What is the average age (age feature) of women? \n",
    "\n",
    "- What is the percentage of German citizens (native-country feature)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male      21790\n",
      "Female    10771\n",
      "Name: sex, dtype: int64\n",
      "36.85823043357163\n",
      "0.004207487485028101\n"
     ]
    }
   ],
   "source": [
    "print(data['sex'].value_counts())\n",
    "print(data.loc[data['sex'] == 'Female', 'age'].mean())\n",
    "print(float((data['native-country'] == 'Germany').sum()) / data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. For people who recieve more than 50K per year (salary feature), what is the mean and standard deviation of their age?  Simiarly for people who receive less than 50K per year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average age of people who earn more than 50k is: 44 +- 10.5 years, people who earn less than 50k - 37 +- 14.0 years.\n"
     ]
    }
   ],
   "source": [
    "ages1 = data.loc[data['salary'] == '>50K', 'age']\n",
    "ages2 = data.loc[data['salary'] == '<=50K', 'age']\n",
    "print(\"The average age of people who earn more than 50k is: {0} +- {1} years, people who earn less than 50k - {2} +- {3} years.\".format(\n",
    "    round(ages1.mean()), round(ages1.std(), 1),\n",
    "    round(ages2.mean()), round(ages2.std(), 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Display the statistics of age for each gender of all the races (race feature). Use groupby() and describe(). Find the maximum age of men of Amer-Indian-Eskimo race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Race: Amer-Indian-Eskimo, sex: Female\n",
      "count    119.000000\n",
      "mean      37.117647\n",
      "std       13.114991\n",
      "min       17.000000\n",
      "25%       27.000000\n",
      "50%       36.000000\n",
      "75%       46.000000\n",
      "max       80.000000\n",
      "Name: age, dtype: float64\n",
      "Race: Amer-Indian-Eskimo, sex: Male\n",
      "count    192.000000\n",
      "mean      37.208333\n",
      "std       12.049563\n",
      "min       17.000000\n",
      "25%       28.000000\n",
      "50%       35.000000\n",
      "75%       45.000000\n",
      "max       82.000000\n",
      "Name: age, dtype: float64\n",
      "Race: Asian-Pac-Islander, sex: Female\n",
      "count    346.000000\n",
      "mean      35.089595\n",
      "std       12.300845\n",
      "min       17.000000\n",
      "25%       25.000000\n",
      "50%       33.000000\n",
      "75%       43.750000\n",
      "max       75.000000\n",
      "Name: age, dtype: float64\n",
      "Race: Asian-Pac-Islander, sex: Male\n",
      "count    693.000000\n",
      "mean      39.073593\n",
      "std       12.883944\n",
      "min       18.000000\n",
      "25%       29.000000\n",
      "50%       37.000000\n",
      "75%       46.000000\n",
      "max       90.000000\n",
      "Name: age, dtype: float64\n",
      "Race: Black, sex: Female\n",
      "count    1555.000000\n",
      "mean       37.854019\n",
      "std        12.637197\n",
      "min        17.000000\n",
      "25%        28.000000\n",
      "50%        37.000000\n",
      "75%        46.000000\n",
      "max        90.000000\n",
      "Name: age, dtype: float64\n",
      "Race: Black, sex: Male\n",
      "count    1569.000000\n",
      "mean       37.682600\n",
      "std        12.882612\n",
      "min        17.000000\n",
      "25%        27.000000\n",
      "50%        36.000000\n",
      "75%        46.000000\n",
      "max        90.000000\n",
      "Name: age, dtype: float64\n",
      "Race: Other, sex: Female\n",
      "count    109.000000\n",
      "mean      31.678899\n",
      "std       11.631599\n",
      "min       17.000000\n",
      "25%       23.000000\n",
      "50%       29.000000\n",
      "75%       39.000000\n",
      "max       74.000000\n",
      "Name: age, dtype: float64\n",
      "Race: Other, sex: Male\n",
      "count    162.000000\n",
      "mean      34.654321\n",
      "std       11.355531\n",
      "min       17.000000\n",
      "25%       26.000000\n",
      "50%       32.000000\n",
      "75%       42.000000\n",
      "max       77.000000\n",
      "Name: age, dtype: float64\n",
      "Race: White, sex: Female\n",
      "count    8642.000000\n",
      "mean       36.811618\n",
      "std        14.329093\n",
      "min        17.000000\n",
      "25%        25.000000\n",
      "50%        35.000000\n",
      "75%        46.000000\n",
      "max        90.000000\n",
      "Name: age, dtype: float64\n",
      "Race: White, sex: Male\n",
      "count    19174.000000\n",
      "mean        39.652498\n",
      "std         13.436029\n",
      "min         17.000000\n",
      "25%         29.000000\n",
      "50%         38.000000\n",
      "75%         49.000000\n",
      "max         90.000000\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for (race, sex), sub_df in data.groupby(['race', 'sex']):\n",
    "    print(\"Race: {0}, sex: {1}\".format(race, sex))\n",
    "    print(sub_df['age'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. As computers understand only numbers, we will do some preprocessing tasks for encoding the categorical features.\n",
    "\n",
    "- Encode Salary column such that wherever we have salary more than 50k that is '>50k' we encode it to 1 else 0. \n",
    "- One hot encode the categorical features.\n",
    "- Split features and target variable into X and y respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['salary'] = data['salary'].apply(lambda x: 1 if x=='>50K' else 0)\n",
    "X = pd.get_dummies(data.drop(\"salary\",1))\n",
    "y = data[[\"salary\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Perform the following operation on dataset.\n",
    "- Split the data X and y into X_train,X_test,y_train and y_test in the ratio 70:30\n",
    "- Further split the training data into train and validation in 80:20 ratio\n",
    "- Then apply the base Decision Tree Classifier model and calculate the accuracy on validation data as well as on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on validation data:  0.8067558675148059\n",
      "Accuracy Score on test data:  0.8128774695465247\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train1, X_val, y_train1, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train1, y_train1)\n",
    "y_pred = clf.predict(X_val)\n",
    "y_pred1 = clf.predict(X_test)\n",
    "print(\"Accuracy Score on validation data: \", accuracy_score(y_val,y_pred))\n",
    "print(\"Accuracy Score on test data: \", accuracy_score(y_test,y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the Effect of adding more trees\n",
    "\n",
    "- Train 3 different ensemble classifiers in the form of gradient boosted trees. Train models with 10, 50 and  100 trees.Use the n_estimators parameter in the boosted tree module.\n",
    "\n",
    "- n-estimators:\n",
    "    - The number of sequential trees to be modeled \n",
    "    - Though GBM is fairly robust at higher number of trees but it can still overfit at a point.\n",
    "\n",
    "- Let's get sarted with a model with n_estimators = 10 and max_depth=6:\n",
    "\n",
    "\n",
    "```python\n",
    "model_10 = GradientBoostingClassifier(n_estimators=10, max_depth=6).fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Perform the following Boosting task on below two models.\n",
    "\n",
    "- Train two models with \n",
    "```python\n",
    "A) n_estimators = 50 & max_depth = 6\n",
    "B) n_estimators =100 & max_depth= 6\n",
    "```\n",
    "- Calculate the accuracy on validation data and testing data.\n",
    "\n",
    "**Things to ponder**\n",
    "\n",
    "- Which model has the best accuracy on the validation data?\n",
    "- Is it always true that the model with the most trees will perform best on validation data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model_10 = GradientBoostingClassifier(n_estimators=10, max_depth=6, random_state=0).fit(X_train1, y_train1)\n",
    "model_50 = GradientBoostingClassifier(n_estimators=50, max_depth=6, random_state=0).fit(X_train1, y_train1)\n",
    "model_100 = GradientBoostingClassifier(n_estimators=100, max_depth=6, random_state=0).fit(X_train1, y_train1)\n",
    "print(\"Accuracy on validation data for model_10: \",model_10.score(X_val,y_val))\n",
    "print(\"Accuracy on validation data for model_50: \",model_50.score(X_val,y_val))\n",
    "print(\"Accuracy on validation data for model_100: \",model_100.score(X_val,y_val))\n",
    "\n",
    "print(\"Accuracy on test data for model_10: \",model_10.score(X_test,y_test))\n",
    "print(\"Accuracy on test data for model_50: \",model_50.score(X_test,y_test))\n",
    "print(\"Accuracy on test data for model_100: \",model_100.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Based on the best gradient boosting classifier you found in the previous task, plot a bar plot of the model's top 10 features with it's feature importance score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = pd.DataFrame({'importance':model_100.feature_importances_})    \n",
    "feat_imp['feature'] = X_train1.columns\n",
    "feat_imp.sort_values(by='importance', ascending=False, inplace=True)\n",
    "feat_imp = feat_imp.iloc[:10]\n",
    "\n",
    "feat_imp.sort_values(by='importance', inplace=True)\n",
    "feat_imp = feat_imp.set_index('feature', drop=True)\n",
    "feat_imp.plot.barh(title=\"Feature Importance\", figsize=(10,5))\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Plot the training and testing error vs. number of trees\n",
    "\n",
    "- Steps to follow:\n",
    "\n",
    "**Step 1: Calculate the classification error for model on the training data (train_data).**\n",
    "\n",
    "**Step 2: Store the training errors into a list (called training_errors) that looks like this:**\n",
    "\n",
    "```python \n",
    "[train_err_10, train_err_50, train_err_100]\n",
    "```\n",
    "**Step 3: Calculate the classification error of each model on the validation data (validation_data).**\n",
    "\n",
    "**Step 4: Store the validation classification error into a list (called validation_errors) that looks like this:**\n",
    "\n",
    "```python\n",
    "[validation_err_10, validation_err_50,validation_err_100]\n",
    "```\n",
    "**Step 5: Calculate the classification error of each model on the test data (test_data).**\n",
    "\n",
    "**Step 6: Store the testing classification error into a list (called testing_errors) that looks like this:**\n",
    "```python\n",
    "[testing_err_10, testing_err_50,testing_err_100]\n",
    "```\n",
    "\n",
    "**Things to ponder**\n",
    "\n",
    "- Does the training error reduce as the number of trees increases?Is it always true that the validation error will reduce as the number of trees increases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_err_10 = 1-model_10.score(X_train,y_train)\n",
    "train_err_50 = 1-model_50.score(X_train,y_train)\n",
    "train_err_100 = 1-model_100.score(X_train,y_train)\n",
    "\n",
    "training_errors = [train_err_10, train_err_50, train_err_100]\n",
    "\n",
    "testing_err_10 = 1-model_10.score(X_test,y_test)\n",
    "testing_err_50 = 1-model_50.score(X_test,y_test)\n",
    "testing_err_100 = 1-model_100.score(X_test,y_test)\n",
    "\n",
    "testing_errors = [testing_err_10, testing_err_50, testing_err_100]\n",
    "\n",
    "validation_err_10 = 1-model_10.score(X_val,y_val)\n",
    "validation_err_50 = 1-model_50.score(X_val,y_val)\n",
    "validation_err_100 = 1-model_100.score(X_val,y_val)\n",
    "\n",
    "validation_errors = [validation_err_10, validation_err_50, validation_err_100]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot([10, 50, 100], training_errors, linewidth=4.0, label='Training error')\n",
    "plt.plot([10, 50, 100], testing_errors, linewidth=4.0, label='Testing error')\n",
    "plt.title('Error vs number of trees')\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('Classification error')\n",
    "plt.legend([\"Training error\",\"Testing error\"])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot([10, 50, 100], training_errors, linewidth=4.0, label='Training error')\n",
    "plt.plot([10, 50, 100], validation_errors, linewidth=4.0, label='Validation error')\n",
    "plt.title('Error vs number of trees')\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('Classification error')\n",
    "plt.legend([\"Training error\",\"Validation error\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
